{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actuals, preds, k):\n",
    "    actuals = set(actuals)\n",
    "    if len(preds) > k:\n",
    "        preds = preds[:k]\n",
    "    total_score = 0\n",
    "    hits = 0\n",
    "    for i, pred in enumerate(preds):\n",
    "        if pred in actuals and preds not in preds[:i]:\n",
    "            hits += 1\n",
    "            total_score += hits / (i + 1)\n",
    "    if len(actuals) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return total_score / min(k, len(actuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare tutorial: https://medium.com/@pds.bangalore/mean-average-precision-abd77d0b9a7e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.5\n",
      "3 0.3333333333333333\n",
      "4 0.375\n",
      "5 0.525\n",
      "6 0.6916666666666667\n",
      "7 0.6916666666666667\n",
      "8 0.6916666666666667\n",
      "9 0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "actuals = list(range(4))\n",
    "preds = [0, 100, 101, 1, 0, 3]\n",
    "for k in range(1, 10):\n",
    "    print(k, apk(actuals, preds, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order of correct cases does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0 1.0\n",
      "2 0.5 0.5\n",
      "3 0.3333333333333333 0.3333333333333333\n",
      "4 0.375 0.375\n",
      "5 0.525 0.525\n",
      "6 0.6916666666666667 0.6916666666666667\n",
      "7 0.6916666666666667 0.6916666666666667\n",
      "8 0.6916666666666667 0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "actuals = list(range(4))\n",
    "preds1 = [0, 100, 101, 1, 2, 3]\n",
    "preds2 = [3, 100, 101, 2, 0, 1]\n",
    "for k in range(1, 9):\n",
    "    print(k, apk(actuals, preds1, k), apk(actuals, preds2, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if not all actuals show up in preds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.5\n",
      "3 0.3333333333333333\n",
      "4 0.375\n",
      "5 0.42000000000000004\n",
      "6 0.5533333333333333\n",
      "7 0.5533333333333333\n",
      "8 0.5533333333333333\n"
     ]
    }
   ],
   "source": [
    "actuals = list(range(5))\n",
    "preds = [0, 100, 101, 1, 2, 3]\n",
    "for k in range(1, 9):\n",
    "    print(k, apk(actuals, preds, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More actuals (10), not all of them showing up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.5\n",
      "3 0.3333333333333333\n",
      "4 0.375\n",
      "5 0.42000000000000004\n",
      "6 0.4611111111111111\n",
      "7 0.3952380952380952\n",
      "8 0.3458333333333333\n",
      "9 0.3074074074074074\n",
      "10 0.27666666666666667\n",
      "11 0.27666666666666667\n",
      "12 0.27666666666666667\n"
     ]
    }
   ],
   "source": [
    "actuals = list(range(10))\n",
    "preds = [3, 100, 101, 1, 0, 2]\n",
    "for k in range(1, 13):\n",
    "    print(k, apk(actuals, preds, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the above two: if you had picked a smaller k (e.g., 10) than number of actuals (e.g., 20), you don't punish the missing actuals beyond k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0 1.0 1.0\n",
      "2 0.5 0.5 0.5\n",
      "3 0.3333333333333333 0.3333333333333333 0.3333333333333333\n",
      "4 0.375 0.375 0.375\n",
      "5 0.525 0.42000000000000004 0.42000000000000004\n",
      "6 0.6916666666666667 0.5533333333333333 0.4611111111111111\n",
      "7 0.6916666666666667 0.5533333333333333 0.3952380952380952\n",
      "8 0.6916666666666667 0.5533333333333333 0.3458333333333333\n",
      "9 0.6916666666666667 0.5533333333333333 0.3074074074074074\n",
      "10 0.6916666666666667 0.5533333333333333 0.27666666666666667\n",
      "11 0.6916666666666667 0.5533333333333333 0.27666666666666667\n",
      "12 0.6916666666666667 0.5533333333333333 0.27666666666666667\n"
     ]
    }
   ],
   "source": [
    "actuals0 = list(range(4))\n",
    "actuals1 = list(range(5))\n",
    "actuals2 = list(range(10))\n",
    "preds = [3, 100, 101, 1, 0, 2]\n",
    "for k in range(1, 13):\n",
    "    print(k, apk(actuals0, preds, k), apk(actuals1, preds, k), apk(actuals2, preds, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap(actuals, preds, debug=False):\n",
    "    actuals = set(actuals)\n",
    "    num_actuals = len(actuals)\n",
    "    recall_at_k = 0\n",
    "    precision_at_k = 0\n",
    "    hits = 0\n",
    "    precisions = []\n",
    "    for i, pred in enumerate(preds):\n",
    "        k = i + 1\n",
    "        if pred in actuals and pred not in preds[:i]:\n",
    "            hit = True\n",
    "            hits += 1\n",
    "        else:\n",
    "            hit = False\n",
    "        \n",
    "        recall_at_k = hits / num_actuals\n",
    "        precision_at_k = hits / k\n",
    "        \n",
    "        if hit:\n",
    "            precisions.append(precision_at_k)\n",
    "        \n",
    "        if debug: print('R@K: %.2f P@K: %.2f - %s' % (recall_at_k, precision_at_k, hit) )\n",
    "        \n",
    "        if recall_at_k == 1:\n",
    "            break\n",
    "            \n",
    "    if recall_at_k != 1:\n",
    "        raise ValueError(\"Recall did not reach 1 after all predictions have been checked!\")\n",
    "    \n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to tutorial: https://ils.unc.edu/courses/2013_spring/inls509_001/lectures/10-EvaluationMetrics.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@K: 0.10 P@K: 1.00 - True\n",
      "R@K: 0.10 P@K: 0.50 - False\n",
      "R@K: 0.20 P@K: 0.67 - True\n",
      "R@K: 0.30 P@K: 0.75 - True\n",
      "R@K: 0.40 P@K: 0.80 - True\n",
      "R@K: 0.50 P@K: 0.83 - True\n",
      "R@K: 0.60 P@K: 0.86 - True\n",
      "R@K: 0.60 P@K: 0.75 - False\n",
      "R@K: 0.70 P@K: 0.78 - True\n",
      "R@K: 0.70 P@K: 0.70 - False\n",
      "R@K: 0.80 P@K: 0.73 - True\n",
      "R@K: 0.80 P@K: 0.67 - False\n",
      "R@K: 0.80 P@K: 0.62 - False\n",
      "R@K: 0.90 P@K: 0.64 - True\n",
      "R@K: 0.90 P@K: 0.60 - False\n",
      "R@K: 0.90 P@K: 0.56 - False\n",
      "R@K: 0.90 P@K: 0.53 - False\n",
      "R@K: 0.90 P@K: 0.50 - False\n",
      "R@K: 0.90 P@K: 0.47 - False\n",
      "R@K: 1.00 P@K: 0.50 - True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7555050505050506"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = list(range(10))\n",
    "preds = [0, 100, 1, 2, 3, 4, 5, 101, 6, 102, 7, 103, 104, 8, 105, 106, 107, 108, 109, 9]\n",
    "ap(actuals, preds, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raise an exception if not all actuals are in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@K: 0.10 P@K: 1.00 - True\n",
      "R@K: 0.10 P@K: 0.50 - False\n",
      "R@K: 0.20 P@K: 0.67 - True\n",
      "R@K: 0.30 P@K: 0.75 - True\n",
      "R@K: 0.40 P@K: 0.80 - True\n",
      "R@K: 0.50 P@K: 0.83 - True\n",
      "R@K: 0.60 P@K: 0.86 - True\n",
      "R@K: 0.60 P@K: 0.75 - False\n",
      "R@K: 0.70 P@K: 0.78 - True\n",
      "R@K: 0.70 P@K: 0.70 - False\n",
      "R@K: 0.80 P@K: 0.73 - True\n",
      "R@K: 0.80 P@K: 0.67 - False\n",
      "R@K: 0.80 P@K: 0.62 - False\n",
      "R@K: 0.90 P@K: 0.64 - True\n",
      "R@K: 0.90 P@K: 0.60 - False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Recall did not reach 1 after all predictions have been checked!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-791bec68a8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m102\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m103\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m105\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-220-1b61316effd1>\u001b[0m in \u001b[0;36map\u001b[0;34m(actuals, preds, debug)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecall_at_k\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall did not reach 1 after all predictions have been checked!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Recall did not reach 1 after all predictions have been checked!"
     ]
    }
   ],
   "source": [
    "actuals = list(range(10))\n",
    "preds = [0, 100, 1, 2, 3, 4, 5, 101, 6, 102, 7, 103, 104, 8, 105]\n",
    "ap(actuals, preds, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing AP and APK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case when all actuals are in preds, APK == AP for big k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.5\n",
      "3 0.5555555555555555\n",
      "4 0.6041666666666666\n",
      "5 0.6433333333333333\n",
      "6 0.6749999999999999\n",
      "7 0.7010204081632653\n",
      "8 0.6133928571428571\n",
      "9 0.6316578483245149\n",
      "10 0.5684920634920634\n",
      "11 0.6412193362193361\n",
      "12 0.6412193362193361\n",
      "13 0.6412193362193361\n",
      "14 0.7055050505050505\n",
      "15 0.7055050505050505\n",
      "16 0.7055050505050505\n",
      "17 0.7055050505050505\n",
      "18 0.7055050505050505\n",
      "19 0.7055050505050505\n",
      "20 0.7555050505050505\n",
      "21 0.7555050505050505\n",
      "22 0.7555050505050505\n"
     ]
    }
   ],
   "source": [
    "actuals = list(range(10))\n",
    "preds = [0, 100, 1, 2, 3, 4, 5, 101, 6, 102, 7, 103, 104, 8, 105, 106, 107, 108, 109, 9]\n",
    "for k in range(1, 23):\n",
    "    rslt = apk(actuals, preds, k)\n",
    "    print(k, rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555050505050506"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap(actuals, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of more cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7838945005611673, 0.7838945005611673)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = list(range(9))\n",
    "preds = [0, 100, 1, 2, 3, 4, 5, 101, 6, 102, 7, 103, 104, 8, 105]\n",
    "apk(actuals, preds, 100), ap(actuals, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8015241702741702, 0.8015241702741703)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = list(range(8))\n",
    "preds = [0, 100, 1, 2, 3, 4, 5, 101, 6, 102, 7, 103, 104, 8]\n",
    "apk(actuals, preds, 100), ap(actuals, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8121315192743763, 0.8121315192743763)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = list(range(7))\n",
    "preds = [0, 100, 1, 2, 3, 4, 5, 101, 6, 102, 7, 103]\n",
    "apk(actuals, preds, 100), ap(actuals, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://ils.unc.edu/courses/2013_spring/inls509_001/lectures/10-EvaluationMetrics.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
